{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_json('Health_and_Personal_Care_5.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['Date'] = pd.to_datetime(reviews['unixReviewTime'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Handy little gadget</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>2011-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "      <td>1329523200</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>2012-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>Very good but not great</td>\n",
       "      <td>1275955200</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>2010-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1XZUG7DFXXOS4</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cat lover</td>\n",
       "      <td>[56, 60]</td>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great addition to your purse</td>\n",
       "      <td>1202428800</td>\n",
       "      <td>02 8, 2008</td>\n",
       "      <td>2008-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1MS3M7M7AM13X</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cricketoes</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very nice and convenient.</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>08 16, 2011</td>\n",
       "      <td>2011-08-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                reviewerName   helpful  \\\n",
       "0   ALC5GH8CAMAI7  159985130X                        AnnN    [1, 1]   \n",
       "1   AHKSURW85PJUE  159985130X         AZ buyer \"AZ buyer\"    [1, 1]   \n",
       "2   A38RMU1Y5TDP9  159985130X  Bob Tobias \"Robert Tobias\"  [75, 77]   \n",
       "3  A1XZUG7DFXXOS4  159985130X                   Cat lover  [56, 60]   \n",
       "4  A1MS3M7M7AM13X  159985130X                  Cricketoes    [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is a great little gadget to have around. ...        5   \n",
       "1  I would recommend this for a travel magnifier ...        4   \n",
       "2  What I liked was the quality of the lens and t...        4   \n",
       "3  Love the Great point light pocket magnifier!  ...        4   \n",
       "4  This is very nice. You pull out on the magnifi...        5   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \\\n",
       "0                    Handy little gadget      1294185600   01 5, 2011   \n",
       "1  Small & may need to encourage battery      1329523200  02 18, 2012   \n",
       "2                Very good but not great      1275955200   06 8, 2010   \n",
       "3           great addition to your purse      1202428800   02 8, 2008   \n",
       "4              Very nice and convenient.      1313452800  08 16, 2011   \n",
       "\n",
       "        Date  \n",
       "0 2011-01-05  \n",
       "1 2012-02-18  \n",
       "2 2010-06-08  \n",
       "3 2008-02-08  \n",
       "4 2011-08-16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346355, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique products:  18534\n",
      "unique users:  38609\n",
      "unique reviews:  38609\n",
      "timeframe:  2000-12-09 00:00:00  -  2014-07-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"unique products: \", reviews['asin'].nunique())\n",
    "print(\"unique users: \", reviews['reviewerID'].nunique())\n",
    "print(\"unique reviews: \", reviews['reviewerID'].nunique())\n",
    "print(\"timeframe: \", reviews['Date'].min(), \" - \", reviews['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>B0037KMI0U</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>B0010JLMO8</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8105</th>\n",
       "      <td>B001KXZ808</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12260</th>\n",
       "      <td>B0049LUI9O</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>B000GIPJY8</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  counts\n",
       "10706  B0037KMI0U    1089\n",
       "5308   B0010JLMO8     767\n",
       "8105   B001KXZ808     699\n",
       "12260  B0049LUI9O     528\n",
       "3114   B000GIPJY8     475"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produts with most reviews\n",
    "reviews.groupby(['asin']).size().reset_index(name='counts').sort_values('counts',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName      3051\n",
       "helpful              0\n",
       "reviewText           0\n",
       "overall              0\n",
       "summary              0\n",
       "unixReviewTime       0\n",
       "reviewTime           0\n",
       "Date                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NA\n",
    "reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with n't\n",
    "def n_apostrophe_t_handler(document):\n",
    "\n",
    "    i = 0\n",
    "    while i < len(document):\n",
    "        if \"n't\" in document[i]:        \n",
    "            # Checks to see if there is a following word after word ending in \"n't\"\n",
    "            if (i+1) < len(document):\n",
    "                document[i+1] = 'not_' + document[i+1]\n",
    "                document.pop(i)\n",
    "            else:\n",
    "                document.pop(i)\n",
    "        i+=1\n",
    "\n",
    "    return(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numbers\n",
    "#input_str = ’Box A contains 3 red and 5 white balls, while Box B contains 4 red and 2 blue balls.’\n",
    "def remove_number(document):\n",
    "    result = re.sub(r'\\d+', '', document)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  we bought one for road trips and trying to interpret maps without having to strain our eyes. really nice design, good tactile feel. i couldn't figure out where the batteries were, sent lightwedge customer service an email and received a response within 24 hours. if you need one i'd recommend this one. \n",
      "\n",
      "numbers:  we bought one for road trips and trying to interpret maps without having to strain our eyes. really nice design, good tactile feel. i couldn't figure out where the batteries were, sent lightwedge customer service an email and received a response within  hours. if you need one i'd recommend this one. \n",
      "\n",
      "tokenization:  ['we', 'bought', 'one', 'for', 'road', 'trips', 'and', 'trying', 'to', 'interpret', 'maps', 'without', 'having', 'to', 'strain', 'our', 'eyes', '.', 'really', 'nice', 'design', ',', 'good', 'tactile', 'feel', '.', 'i', 'could', \"n't\", 'figure', 'out', 'where', 'the', 'batteries', 'were', ',', 'sent', 'lightwedge', 'customer', 'service', 'an', 'email', 'and', 'received', 'a', 'response', 'within', 'hours', '.', 'if', 'you', 'need', 'one', 'i', \"'d\", 'recommend', 'this', 'one', '.'] \n",
      "\n",
      "negation:  ['we', 'bought', 'one', 'for', 'road', 'trips', 'and', 'trying', 'to', 'interpret', 'maps', 'without', 'having', 'to', 'strain', 'our', 'eyes', '.', 'really', 'nice', 'design', ',', 'good', 'tactile', 'feel', '.', 'i', 'could', 'not_figure', 'out', 'where', 'the', 'batteries', 'were', ',', 'sent', 'lightwedge', 'customer', 'service', 'an', 'email', 'and', 'received', 'a', 'response', 'within', 'hours', '.', 'if', 'you', 'need', 'one', 'i', \"'d\", 'recommend', 'this', 'one', '.'] \n",
      "\n",
      "punctuation:  ['we', 'bought', 'one', 'for', 'road', 'trips', 'and', 'trying', 'to', 'interpret', 'maps', 'without', 'having', 'to', 'strain', 'our', 'eyes', 'really', 'nice', 'design', 'good', 'tactile', 'feel', 'i', 'could', 'not_figure', 'out', 'where', 'the', 'batteries', 'were', 'sent', 'lightwedge', 'customer', 'service', 'an', 'email', 'and', 'received', 'a', 'response', 'within', 'hours', 'if', 'you', 'need', 'one', 'i', 'd', 'recommend', 'this', 'one'] \n",
      "\n",
      "stop words:  ['bought', 'one', 'road', 'trips', 'trying', 'interpret', 'maps', 'without', 'strain', 'eyes', 'really', 'nice', 'design', 'good', 'tactile', 'feel', 'could', 'not_figure', 'batteries', 'sent', 'lightwedge', 'customer', 'service', 'email', 'received', 'response', 'within', 'hours', 'need', 'one', 'recommend', 'one'] \n",
      "\n",
      "stemming:   ['bought', 'one', 'road', 'trip', 'tri', 'interpret', 'map', 'without', 'strain', 'eye', 'realli', 'nice', 'design', 'good', 'tactil', 'feel', 'could', 'not_figur', 'batteri', 'sent', 'lightwedg', 'custom', 'servic', 'email', 'receiv', 'respons', 'within', 'hour', 'need', 'one', 'recommend', 'one'] \n",
      "\n",
      "lemmatizer:   ['bought', 'one', 'road', 'trip', 'tri', 'interpret', 'map', 'without', 'strain', 'eye', 'realli', 'nice', 'design', 'good', 'tactil', 'feel', 'could', 'not_figur', 'batteri', 'sent', 'lightwedg', 'custom', 'servic', 'email', 'receiv', 'respons', 'within', 'hour', 'need', 'one', 'recommend', 'one'] \n",
      "\n",
      "remove empty:   ['bought', 'one', 'road', 'trip', 'tri', 'interpret', 'map', 'without', 'strain', 'eye', 'realli', 'nice', 'design', 'good', 'tactil', 'feel', 'could', 'not_figur', 'batteri', 'sent', 'lightwedg', 'custom', 'servic', 'email', 'receiv', 'respons', 'within', 'hour', 'need', 'one', 'recommend', 'one'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text to lower case \n",
    "review_text = reviews[\"reviewText\"].str.lower()\n",
    "print(\"original: \",review_text[7],\"\\n\")\n",
    "\n",
    "# remove numbers\n",
    "review_text = review_text.apply(remove_number)\n",
    "print(\"numbers: \",review_text[7],\"\\n\")\n",
    "\n",
    "# words Tokenization\n",
    "review_text = review_text.apply(word_tokenize)\n",
    "print(\"tokenization: \",review_text[7],\"\\n\")\n",
    "\n",
    "# deal with negation\n",
    "review_text = review_text.apply(n_apostrophe_t_handler)\n",
    "print(\"negation: \",review_text[7],\"\\n\")\n",
    "\n",
    "# remove punctuation\n",
    "punctuations = list(string.punctuation)\n",
    "review_text = review_text.apply(lambda x: \n",
    "           [i.strip(\"\".join(punctuations)) for i in x if i not in punctuations])\n",
    "print(\"punctuation: \", review_text[7],\"\\n\")\n",
    "\n",
    "# remove stop words \n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "review_text = review_text.apply(lambda x: \n",
    "                             [item for item in x if item not in stop_words])\n",
    "print(\"stop words: \",review_text[7],\"\\n\")\n",
    "\n",
    "# word stemming\n",
    "stemmer = PorterStemmer()\n",
    "review_text = review_text.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "print(\"stemming:  \",review_text[7],\"\\n\")\n",
    "\n",
    "# lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "review_text = review_text.apply(lambda x: [lemmatizer.lemmatize(y) for y in x])\n",
    "print(\"lemmatizer:  \",review_text[7],\"\\n\")\n",
    "\n",
    "# remove empty string\n",
    "for i in range(len(review_text)):\n",
    "    review_text[i] = [x for x in review_text[i] if x]\n",
    "print(\"remove empty:  \",review_text[7],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_clean = review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "vec=[]\n",
    "for i in range(len(review_clean)):\n",
    "    for j in range(len(review_clean[i])):\n",
    "        vec.append(review_clean[i][j]) \n",
    "freq = FreqDist(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use</td>\n",
       "      <td>276456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "      <td>173446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>144143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>143951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work</td>\n",
       "      <td>135202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frequency\n",
       "0      use     276456\n",
       "1  product     173446\n",
       "2      one     144143\n",
       "3     like     143951\n",
       "4     work     135202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq = pd.DataFrame(freq.most_common(500),columns=['Word','Frequency'])\n",
    "most_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = most_freq['Word'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele + \" \" \n",
    "    # return string   \n",
    "    return str1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_clean_str = review_clean.apply(listToString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True, vocabulary = vocabulary)\n",
    "cv.fit(review_clean_str)\n",
    "X_bow = cv.transform(review_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346355, 500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>use</th>\n",
       "      <th>product</th>\n",
       "      <th>one</th>\n",
       "      <th>like</th>\n",
       "      <th>work</th>\n",
       "      <th>get</th>\n",
       "      <th>take</th>\n",
       "      <th>good</th>\n",
       "      <th>would</th>\n",
       "      <th>great</th>\n",
       "      <th>...</th>\n",
       "      <th>stand</th>\n",
       "      <th>claim</th>\n",
       "      <th>measur</th>\n",
       "      <th>simpli</th>\n",
       "      <th>gone</th>\n",
       "      <th>difficult</th>\n",
       "      <th>absorb</th>\n",
       "      <th>odor</th>\n",
       "      <th>famili</th>\n",
       "      <th>idea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALC5GH8CAMAI7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AHKSURW85PJUE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A38RMU1Y5TDP9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1XZUG7DFXXOS4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1MS3M7M7AM13X</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXO4PQU0XG3TG</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A28X0LT2100RL1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1VUSWRVN8SJA8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1JQDCX4LDKBZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3RNRXOM5J2C93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                use  product  one  like  work  get  take  good  would  great  \\\n",
       "reviewerID                                                                     \n",
       "ALC5GH8CAMAI7     1        0    1     0     0    0     0     0      0      1   \n",
       "AHKSURW85PJUE     0        0    1     1     0    0     1     0      1      1   \n",
       "A38RMU1Y5TDP9     1        0    0     1     1    0     1     1      0      1   \n",
       "A1XZUG7DFXXOS4    0        0    0     0     1    0     0     0      1      1   \n",
       "A1MS3M7M7AM13X    0        0    0     0     0    0     0     0      1      0   \n",
       "AXO4PQU0XG3TG     1        0    0     0     0    0     0     0      0      0   \n",
       "A28X0LT2100RL1    1        0    0     1     0    0     1     1      0      0   \n",
       "A1VUSWRVN8SJA8    0        0    1     0     0    0     0     1      0      0   \n",
       "A1JQDCX4LDKBZ3    0        0    0     0     1    0     0     0      1      0   \n",
       "A3RNRXOM5J2C93    0        0    0     0     0    0     0     0      0      0   \n",
       "\n",
       "                ...  stand  claim  measur  simpli  gone  difficult  absorb  \\\n",
       "reviewerID      ...                                                          \n",
       "ALC5GH8CAMAI7   ...      0      0       0       0     0          0       0   \n",
       "AHKSURW85PJUE   ...      0      0       0       0     0          0       0   \n",
       "A38RMU1Y5TDP9   ...      0      0       0       0     0          0       0   \n",
       "A1XZUG7DFXXOS4  ...      0      0       0       0     0          0       0   \n",
       "A1MS3M7M7AM13X  ...      0      0       0       0     0          0       0   \n",
       "AXO4PQU0XG3TG   ...      0      0       0       0     0          0       0   \n",
       "A28X0LT2100RL1  ...      0      0       0       0     0          0       0   \n",
       "A1VUSWRVN8SJA8  ...      0      0       0       0     0          0       0   \n",
       "A1JQDCX4LDKBZ3  ...      0      0       0       0     0          0       0   \n",
       "A3RNRXOM5J2C93  ...      0      0       0       0     0          0       0   \n",
       "\n",
       "                odor  famili  idea  \n",
       "reviewerID                          \n",
       "ALC5GH8CAMAI7      0       0     0  \n",
       "AHKSURW85PJUE      0       0     0  \n",
       "A38RMU1Y5TDP9      0       0     0  \n",
       "A1XZUG7DFXXOS4     0       0     0  \n",
       "A1MS3M7M7AM13X     0       0     0  \n",
       "AXO4PQU0XG3TG      0       0     0  \n",
       "A28X0LT2100RL1     0       0     0  \n",
       "A1VUSWRVN8SJA8     0       0     0  \n",
       "A1JQDCX4LDKBZ3     0       0     0  \n",
       "A3RNRXOM5J2C93     0       0     0  \n",
       "\n",
       "[10 rows x 500 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_df = pd.DataFrame(X_bow.toarray(), index = reviews['reviewerID'], columns = vocabulary)\n",
    "bag_of_words_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer(ngram_range = (1, 1), vocabulary = vocabulary).fit(review_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'word': tfidf_model.get_feature_names(), 'tfidf': list(tfidf_model.idf_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use</td>\n",
       "      <td>1.821326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "      <td>2.179951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>2.303672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>2.247320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work</td>\n",
       "      <td>2.236394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     tfidf\n",
       "0      use  1.821326\n",
       "1  product  2.179951\n",
       "2      one  2.303672\n",
       "3     like  2.247320\n",
       "4     work  2.236394"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ngram = TfidfVectorizer(ngram_range = (1, 2), max_features = 1000).fit(review_clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame({'word': tfidf_ngram.get_feature_names(), 'tfidf': list(tfidf_ngram.idf_)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abl</td>\n",
       "      <td>4.296929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absolut</td>\n",
       "      <td>5.054542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absorb</td>\n",
       "      <td>5.095142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accur</td>\n",
       "      <td>5.230855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acid</td>\n",
       "      <td>5.198424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word     tfidf\n",
       "0      abl  4.296929\n",
       "1  absolut  5.054542\n",
       "2   absorb  5.095142\n",
       "3    accur  5.230855\n",
       "4     acid  5.198424"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['review_clean_list'] = review_clean\n",
    "reviews['review_clean_str'] = review_clean_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whn97\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\whn97\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# classify sentiment into positive and negative ones\n",
    "reviews['sentiment'] = ''\n",
    "reviews['sentiment'][reviews['overall'] >= 4] = 'positive'\n",
    "#test['sentiment'][test['polarity'] == 0] = 'neutral'\n",
    "reviews['sentiment'][reviews['overall'] < 4] = 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>review_clean_list</th>\n",
       "      <th>review_clean_str</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Handy little gadget</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>[great, littl, gadget, around, alreadi, use, l...</td>\n",
       "      <td>great littl gadget around alreadi use look spl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "      <td>1329523200</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>2012-02-18</td>\n",
       "      <td>[would, recommend, travel, magnifi, occasion, ...</td>\n",
       "      <td>would recommend travel magnifi occasion readin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>Very good but not great</td>\n",
       "      <td>1275955200</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>2010-06-08</td>\n",
       "      <td>[like, qualiti, len, built, light, len, discer...</td>\n",
       "      <td>like qualiti len built light len discern disto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1XZUG7DFXXOS4</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cat lover</td>\n",
       "      <td>[56, 60]</td>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great addition to your purse</td>\n",
       "      <td>1202428800</td>\n",
       "      <td>02 8, 2008</td>\n",
       "      <td>2008-02-08</td>\n",
       "      <td>[love, great, point, light, pocket, magnifi, w...</td>\n",
       "      <td>love great point light pocket magnifi work gre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1MS3M7M7AM13X</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cricketoes</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very nice and convenient.</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>08 16, 2011</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>[nice, pull, magnifi, want, light, come, slide...</td>\n",
       "      <td>nice pull magnifi want light come slide back w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                reviewerName   helpful  \\\n",
       "0   ALC5GH8CAMAI7  159985130X                        AnnN    [1, 1]   \n",
       "1   AHKSURW85PJUE  159985130X         AZ buyer \"AZ buyer\"    [1, 1]   \n",
       "2   A38RMU1Y5TDP9  159985130X  Bob Tobias \"Robert Tobias\"  [75, 77]   \n",
       "3  A1XZUG7DFXXOS4  159985130X                   Cat lover  [56, 60]   \n",
       "4  A1MS3M7M7AM13X  159985130X                  Cricketoes    [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This is a great little gadget to have around. ...        5   \n",
       "1  I would recommend this for a travel magnifier ...        4   \n",
       "2  What I liked was the quality of the lens and t...        4   \n",
       "3  Love the Great point light pocket magnifier!  ...        4   \n",
       "4  This is very nice. You pull out on the magnifi...        5   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \\\n",
       "0                    Handy little gadget      1294185600   01 5, 2011   \n",
       "1  Small & may need to encourage battery      1329523200  02 18, 2012   \n",
       "2                Very good but not great      1275955200   06 8, 2010   \n",
       "3           great addition to your purse      1202428800   02 8, 2008   \n",
       "4              Very nice and convenient.      1313452800  08 16, 2011   \n",
       "\n",
       "        Date                                  review_clean_list  \\\n",
       "0 2011-01-05  [great, littl, gadget, around, alreadi, use, l...   \n",
       "1 2012-02-18  [would, recommend, travel, magnifi, occasion, ...   \n",
       "2 2010-06-08  [like, qualiti, len, built, light, len, discer...   \n",
       "3 2008-02-08  [love, great, point, light, pocket, magnifi, w...   \n",
       "4 2011-08-16  [nice, pull, magnifi, want, light, come, slide...   \n",
       "\n",
       "                                    review_clean_str sentiment  \n",
       "0  great littl gadget around alreadi use look spl...  positive  \n",
       "1  would recommend travel magnifi occasion readin...  positive  \n",
       "2  like qualiti len built light len discern disto...  positive  \n",
       "3  love great point light pocket magnifi work gre...  positive  \n",
       "4  nice pull magnifi want light come slide back w...  positive  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     66554\n",
       "positive    279801\n",
       "Name: reviewText, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment \n",
    "reviews.groupby('sentiment').reviewText.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop Sentiment Analysis predictive models (binary classification) in Python, using Jupyter Notebook or any other\n",
    "tool of your choice. Apply LogisticRegression, SVM, RandomForest classification algorithms (you can also choose any\n",
    "three classification algorithms of your choice). Apply Data Science Process Model as a guide. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = pd.get_dummies(reviews['sentiment'],drop_first=True)   #reduce one degree of freedom\n",
    "reviews['dummy_y'] = dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bag_of_words_df\n",
    "y = reviews['dummy_y']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y ,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.83157\n"
     ]
    }
   ],
   "source": [
    "# The default logistic regression\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logistic.predict(X_test)\n",
    "y_score = logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(logistic.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune parameters\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "params = {'C':[0.0001, 1, 100, 1000],\n",
    "          'max_iter':[1, 10, 100, 500],\n",
    "          'class_weight':['balanced', None],\n",
    "          'solver':['liblinear','sag','lbfgs','newton-cg']\n",
    "         }\n",
    "lr = LogisticRegression()\n",
    "grid_search = GridSearchCV(lr, param_grid=params, cv=10)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best logistic model\n",
    "best_model_log = LogisticRegression(**grid_search.best_params_)\n",
    "best_model_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model_log.predict(X_test)\n",
    "y_score = best_model_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of best_model_log classifier on test set: {:.5f}'.format(best_model_log.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "def roc(y_test, y_pred, y_score):\n",
    "    logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc(y_test, y_pred, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default Random Forest\n",
    "rf_class = RandomForestClassifier()\n",
    "rf_class.fit(X_train,y_train)\n",
    "\n",
    "y_pred=rf_class.predict(X_test)\n",
    "y_score = rf_class.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of RF classifier on test set: {:.5f}'.format(rf_class.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tune parameters\n",
    "params = {\"max_depth\": range(10,50,3),\n",
    "           \"n_estimators\": range(10,50,3),\n",
    "           'criterion' :['gini', 'entropy'],\n",
    "           'max_features': ['auto', 'sqrt', 'log2']\n",
    "          }\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid=params, cv=10)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best RF \n",
    "best_model_rf = RandomForestClassifier(**grid_search.best_params_,)\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model_rf.predict(X_test)\n",
    "y_score = best_model_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of best_model_rf classifier on test set: {:.5f}'.format(best_model_rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute precision, recall, F-measure and support\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "roc(y_test, y_pred, y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default SVM model\n",
    "from sklearn import svm\n",
    "\n",
    "svmclf = svm.SVC()\n",
    "svmclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svmclf.predict(X_test)\n",
    "y_score = logistic.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of SVM classifier on test set: {:.5f}'.format(svmclf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune parameters\n",
    "params = [{'kernel': ['rbf'], 'gamma': [0.001, 0.0001],'C': [1, 10, 100, 1000]},\n",
    "          {'kernel': ['linear'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n",
    "svm = svm.SVC()\n",
    "grid_search = GridSearchCV(svm, param_grid=params, cv=10)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best svm model\n",
    "from sklearn import svm\n",
    "best_model_svm = svm.SVC(**grid_search.best_params_,probability=True)\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model_svm.predict(X_test)\n",
    "y_score = best_model_svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Accuracy of best_model_svm classifier on test set: {:.5f}'.format(best_model_svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute precision, recall, F-measure and support\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc(y_test, y_pred, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
